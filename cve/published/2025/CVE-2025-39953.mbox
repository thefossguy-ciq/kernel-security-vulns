From bippy-1.2.0 Mon Sep 17 00:00:00 2001
From: Greg Kroah-Hartman <gregkh@kernel.org>
To: <linux-cve-announce@vger.kernel.org>
Reply-to: <cve@kernel.org>, <linux-kernel@vger.kernel.org>
Subject: CVE-2025-39953: cgroup: split cgroup_destroy_wq into 3 workqueues
Message-Id: <2025100421-CVE-2025-39953-4ac6@gregkh>
Content-Length: 4580
Lines: 105
X-Developer-Signature: v=1; a=openpgp-sha256; l=4686;
 i=gregkh@linuxfoundation.org; h=from:subject:message-id;
 bh=PJ5D7jC/tBm81wRYeyZ+pK7Gzk8pzPcKIwixLIf7pSQ=;
 b=owGbwMvMwCRo6H6F97bub03G02pJDBkPzh4880L2hNutBq7Gs/Y7WiYdjJDa0VnyZZ3UkdXmB
 1xWvVd52xHLwiDIxCArpsjyZRvP0f0VhxS9DG1Pw8xhZQIZwsDFKQATMVdkWDA386+dCLftjnNb
 13Ifr5gaE9p3UY5hnprRB1e+r3cnPXP5dyJy2dT3JStEmQE=
X-Developer-Key: i=gregkh@linuxfoundation.org; a=openpgp;
 fpr=F4B60CC5BF78C2214A313DCB3147D40DDB2DFB29

Description
===========

In the Linux kernel, the following vulnerability has been resolved:

cgroup: split cgroup_destroy_wq into 3 workqueues

A hung task can occur during [1] LTP cgroup testing when repeatedly
mounting/unmounting perf_event and net_prio controllers with
systemd.unified_cgroup_hierarchy=1. The hang manifests in
cgroup_lock_and_drain_offline() during root destruction.

Related case:
cgroup_fj_function_perf_event cgroup_fj_function.sh perf_event
cgroup_fj_function_net_prio cgroup_fj_function.sh net_prio

Call Trace:
	cgroup_lock_and_drain_offline+0x14c/0x1e8
	cgroup_destroy_root+0x3c/0x2c0
	css_free_rwork_fn+0x248/0x338
	process_one_work+0x16c/0x3b8
	worker_thread+0x22c/0x3b0
	kthread+0xec/0x100
	ret_from_fork+0x10/0x20

Root Cause:

CPU0                            CPU1
mount perf_event                umount net_prio
cgroup1_get_tree                cgroup_kill_sb
rebind_subsystems               // root destruction enqueues
				// cgroup_destroy_wq
// kill all perf_event css
                                // one perf_event css A is dying
                                // css A offline enqueues cgroup_destroy_wq
                                // root destruction will be executed first
                                css_free_rwork_fn
                                cgroup_destroy_root
                                cgroup_lock_and_drain_offline
                                // some perf descendants are dying
                                // cgroup_destroy_wq max_active = 1
                                // waiting for css A to die

Problem scenario:
1. CPU0 mounts perf_event (rebind_subsystems)
2. CPU1 unmounts net_prio (cgroup_kill_sb), queuing root destruction work
3. A dying perf_event CSS gets queued for offline after root destruction
4. Root destruction waits for offline completion, but offline work is
   blocked behind root destruction in cgroup_destroy_wq (max_active=1)

Solution:
Split cgroup_destroy_wq into three dedicated workqueues:
cgroup_offline_wq – Handles CSS offline operations
cgroup_release_wq – Manages resource release
cgroup_free_wq – Performs final memory deallocation

This separation eliminates blocking in the CSS free path while waiting for
offline operations to complete.

[1] https://github.com/linux-test-project/ltp/blob/master/runtest/controllers

The Linux kernel CVE team has assigned CVE-2025-39953 to this issue.


Affected and fixed versions
===========================

	Issue introduced in 4.6 with commit 334c3679ec4b2b113c35ebe37d2018b112dd5013 and fixed in 6.1.154 with commit 993049c9b1355c78918344a6403427d53f9ee700
	Issue introduced in 4.6 with commit 334c3679ec4b2b113c35ebe37d2018b112dd5013 and fixed in 6.6.108 with commit 4a1e3ec28e8062cd9f339aa6a942df9c5bcb6811
	Issue introduced in 4.6 with commit 334c3679ec4b2b113c35ebe37d2018b112dd5013 and fixed in 6.12.49 with commit ded4d207a3209a834b6831ceec7f39b934c74802
	Issue introduced in 4.6 with commit 334c3679ec4b2b113c35ebe37d2018b112dd5013 and fixed in 6.16.9 with commit 05e0b03447cf215ec384210441b34b7a3b16e8b0
	Issue introduced in 4.6 with commit 334c3679ec4b2b113c35ebe37d2018b112dd5013 and fixed in 6.17 with commit 79f919a89c9d06816dbdbbd168fa41d27411a7f9

Please see https://www.kernel.org for a full list of currently supported
kernel versions by the kernel community.

Unaffected versions might change over time as fixes are backported to
older supported kernel versions.  The official CVE entry at
	https://cve.org/CVERecord/?id=CVE-2025-39953
will be updated if fixes are backported, please check that for the most
up to date information about this issue.


Affected files
==============

The file(s) affected by this issue are:
	kernel/cgroup/cgroup.c


Mitigation
==========

The Linux kernel CVE team recommends that you update to the latest
stable kernel version for this, and many other bugfixes.  Individual
changes are never tested alone, but rather are part of a larger kernel
release.  Cherry-picking individual commits is not recommended or
supported by the Linux kernel community at all.  If however, updating to
the latest release is impossible, the individual changes to resolve this
issue can be found at these commits:
	https://git.kernel.org/stable/c/993049c9b1355c78918344a6403427d53f9ee700
	https://git.kernel.org/stable/c/4a1e3ec28e8062cd9f339aa6a942df9c5bcb6811
	https://git.kernel.org/stable/c/ded4d207a3209a834b6831ceec7f39b934c74802
	https://git.kernel.org/stable/c/05e0b03447cf215ec384210441b34b7a3b16e8b0
	https://git.kernel.org/stable/c/79f919a89c9d06816dbdbbd168fa41d27411a7f9
